(* Functor to build a standalone parser with printers *)

(* Vendor dependencies *)

module Region = Simple_utils.Region
module Utils  = Simple_utils.Utils

(* Generic signature of tokens *)

module type TOKEN =
  sig
    type token
    type t = token

    val to_lexeme : token -> string
    val to_string : offsets:bool -> [`Byte | `Point] -> token -> string
    val to_region : token -> Region.t
    val is_eof    : token -> bool
    val mk_eof    : Region.t -> token
  end

(* Generic signature of input lexers *)

module type LEXER =
  sig
    module Token : TOKEN
    type token = Token.t

    type message = string Region.reg

    val scan : Lexing.lexbuf -> (token, message) Stdlib.result

    type window = <
      last_token    : token option;
      current_token : token           (* Including EOF *)
    >

    val get_window : unit -> window option
  end

(* The signature generated by Menhir with an additional type
   definition for [ast]. *)

module type PARSER =
  sig
    type token
    type tree

    (* The monolithic API. *)

    exception Error

    val main : (Lexing.lexbuf -> token) -> Lexing.lexbuf -> tree

    (* The incremental API. *)

    module MenhirInterpreter : MenhirLib.IncrementalEngine.EVERYTHING
           with type token = token

    module Incremental :
      sig
        val main :
          Lexing.position -> tree MenhirInterpreter.checkpoint
      end


    (* The recovery API. *)

    module Recovery : Merlin_recovery.RECOVERY_GENERATED
           with module I := MenhirInterpreter
  end

(* Parser errors for the Incremental API of Menhir *)

module type PAR_ERR =
  sig
    val message : int -> string
  end

(* Debug setting *)

module type DEBUG_CONFIG =
  sig
    (* Enable debug printing in the recovery algorithm *)
    val error_recovery_tracing : bool
    (* Path to a log file or [None] that means to use stdout *)
    val tracing_output         : string option
  end

(* The functor integrating the parser with its errors *)

module Make (Lexer: LEXER)
            (Parser: PARSER with type token = Lexer.Token.token)
            (Debug: DEBUG_CONFIG) =
  struct
    module Token = Lexer.Token
    type token = Lexer.token

    type message = string Region.reg

    type 'src parser =
      'src -> (Parser.tree, message) Stdlib.result

    (* Errors and error messages *)

    let get_window () : Lexer.window =
      let invalid_eof =
        object
          method last_token    = None
          method current_token = Token.mk_eof Region.ghost
        end in
      match Lexer.get_window () with
        None -> invalid_eof
      | Some window -> window

    (* THE MONOLITHIC API *)

    exception LexingError of message

    let mk_menhir_lexer lexer source =
      match lexer source with
        Stdlib.Ok token -> token
        (* Encoding due to the API generated by Menhir: *)
      | Stdlib.Error msg -> raise (LexingError msg)

    let mono_menhir lexbuf_of source =
      let lexbuf = lexbuf_of source in
      let menhir_lexer = mk_menhir_lexer Lexer.scan in
      try Stdlib.Ok (Parser.main menhir_lexer lexbuf) with
        (* See [mk_menhir_lexer]: *)
        LexingError msg -> Stdlib.Error msg
      | Parser.Error -> (* Menhir exception *)
        let window = get_window () in
        let region = Token.to_region window#current_token
        in Stdlib.Error Region.{value=""; region}

    let mono_from_lexbuf  = mono_menhir (fun x -> x)
    let mono_from_channel = mono_menhir Lexing.from_channel
    let mono_from_string  = mono_menhir Lexing.from_string

    type file_path = string

    let lexbuf_from_file path =
      try
        let in_chan = open_in path in
        let lexbuf  = Lexing.from_channel in_chan in
        let () =
          let open Lexing in
          lexbuf.lex_curr_p <-
            {lexbuf.lex_curr_p with pos_fname=path}
        in Ok (lexbuf, fun () -> close_in in_chan)
      with
        Sys_error msg -> Stdlib.Error (Region.wrap_ghost msg)

    let mono_from_file path =
      match lexbuf_from_file path with
        Stdlib.Error _ as err -> err
      | Ok (lexbuf, close) ->
          let tree = mono_menhir (fun x -> x) lexbuf
          in close (); tree

    (* THE INCREMENTAL API *)

    module Inter = Parser.MenhirInterpreter

    (* The call [state checkpoint] extracts the number of the current
       state out of a parser checkpoint. The case [None] denotes the
       case of an error state with an empty LR stack: Menhir does not
       know how to determine that state. Until this is fixed, we
       return [None] and a generic error message (see function
       [message] below.) *)

    let state checkpoint : int option =
      let stack = function
        Inter.HandlingError env -> Some (Inter.stack env)
      |                       _ -> None in
      let module Stream = MenhirLib.General in
      match stack checkpoint with
        None -> None
      | Some state ->
          let open Stream in
          match Lazy.force state with
            Nil -> None
          | Cons (Inter.Element (s,_,_,_), _) -> Some (Inter.number s)

    (* The parser has suspended itself because of a syntax error. *)

    exception ParsingError of string

    let get_error_message (module ParErr : PAR_ERR) checkpoint : string =
      match state checkpoint with
        (* A MenhirLib limitation (see [state]). Work around. *)
        None -> "Syntax error."
      | Some state ->
         match ParErr.message state with
           (* Default error message (unfinished mapping) *)
           "<YOUR SYNTAX ERROR MESSAGE HERE>\n" ->
            Printf.sprintf "Syntax error #%i." state
         | msg -> msg
         (* Likely a build error, but we work around it: *)
         | exception Not_found -> "Syntax error."

    let raise_on_failure (module ParErr : PAR_ERR) checkpoint =
      let msg = get_error_message (module ParErr) checkpoint
      in raise (ParsingError msg)

    (* The parser has successfully produced a semantic value. *)

    let success v = v

    (* Incremental parsing *)

    let incr_menhir lexbuf_of (module ParErr : PAR_ERR) source =
      let lexbuf       = lexbuf_of source
      and menhir_lexer = mk_menhir_lexer Lexer.scan in
      let supplier     = Inter.lexer_lexbuf_to_supplier menhir_lexer lexbuf in
      let failure      = raise_on_failure (module ParErr) in
      let interpreter  = Inter.loop_handle success failure supplier in
      let module Incr  = Parser.Incremental in
      let parser       = Incr.main lexbuf.Lexing.lex_curr_p in
      let tree =
        try Stdlib.Ok (interpreter parser) with
        (* See [mk_menhir_lexer]: *)
        | LexingError msg -> Stdlib.Error msg
        | ParsingError msg ->
           let window = get_window () in
           let region = Token.to_region window#current_token in
           let msg    = msg ^ "\n"
           in Stdlib.Error Region.{value=msg; region}
      in flush_all (); tree

    let incr_from_lexbuf  = incr_menhir (fun x -> x)
    let incr_from_channel = incr_menhir Lexing.from_channel
    let incr_from_string  = incr_menhir Lexing.from_string

    let incr_from_file (module ParErr : PAR_ERR) path =
      match lexbuf_from_file path with
        Stdlib.Error _ as err -> err
      | Ok (lexbuf, close) ->
         let tree = incr_from_lexbuf (module ParErr) lexbuf
         in close (); tree


    (* Incremental parsing with recovery *)

    type 'src recovery_parser =
      'src -> (Parser.tree * message list, message Utils.nseq) Stdlib.result
    (* returns [Ok (tree, [])] if ['src] contains correct contract
            or [Ok (repaired_tree, errors)] if any syntax error was encountered
            or [Error (errors)] if non-syntax error happened and we cannot
               return any tree (e. g. file does not found or lexer error) *)

     let extract_recovery_results = function
       | Ok (tree, msgs) -> Some tree, msgs
       | Error (msgs)    -> None,      Utils.nseq_to_list msgs

    (* Debug printer *)

    let tracing_channel =
      match Debug.tracing_output with
      | None      -> stdout
      | Some path -> open_out path

    module TracingPrinter : Merlin_recovery.PRINTER with module I = Inter
      = Merlin_recovery.MakePrinter
            (struct
                module I = Inter
                let print str =
                  if Debug.error_recovery_tracing then
                      Printf.fprintf tracing_channel "%s" str

                let print_symbol = function
                  | Inter.X s -> print @@ Parser.Recovery.print_symbol s

                let print_element = None

                let print_token t = print @@ Lexer.Token.to_lexeme t
            end)


    module R = Merlin_recovery.Make
                   (Inter)
                   (struct
                       include Parser.Recovery

                       let default_value _loc sym =
                         default_value sym
                       (* TODO *)

                       let guide _ = false
                    end)
                   (TracingPrinter)

    module Recover =
      struct
        type 'a parser =
          | Correct of 'a Inter.checkpoint
          | Recovering of 'a Inter.checkpoint * 'a R.candidates
            (* [Recovering (failure_checkpoint, candidates)]  *)

        type 'a step =
          | Intermediate of 'a parser
          | Success of 'a
          | Error of 'a Inter.checkpoint

        let rec normalize checkpoint =
          match checkpoint with
          | Inter.InputNeeded _ -> Intermediate (Correct checkpoint)
          | Inter.Accepted x    -> Success x
          | Inter.HandlingError _ | Inter.Rejected        -> Error checkpoint
          | Inter.Shifting _      | Inter.AboutToReduce _ ->
             normalize (Inter.resume checkpoint)

        let recovery_env = function
          | Inter.InputNeeded env -> env
          | _ -> assert false

        let step parser failure token : 'a step * message option =
          let try_recovery failure_cp candidates: 'a step =
            begin match R.attempt candidates token with
            | `Ok (Inter.InputNeeded _ as cp, _) ->
               Intermediate (Correct cp)
            | `Ok _     -> failwith "Impossible"
            | `Accept x -> Success x
            | `Fail ->
               begin match token with
               | token, _, _ when Token.is_eof token ->
                  begin match candidates.final with
                  | Some x -> Success x
                  | None -> Error failure_cp (* Fatal error *)
                  end
               (* If recovering fails skip token and try again. *)
               | _ ->
                  Intermediate (Recovering (failure_cp, candidates))
               end
            end in
          match parser with
          | Correct cp ->
             begin match normalize (Inter.offer cp token) with
             | Intermediate _ | Success _ as s -> (s, None)
             | Error failure_cp ->
                let error = failure failure_cp in
                TracingPrinter.print @@ Printf.sprintf "Error %s\n" error.Region.value;
                let env = recovery_env cp in
                let candidates = R.generate env in
                (try_recovery failure_cp candidates, Some error)
             end
          | Recovering (failure_cp, candidates) ->
             (try_recovery failure_cp candidates, None)

        let loop_handle
                (success : 'a -> 'a) (failure : 'a Inter.checkpoint -> message)
                (supplier : unit -> token * Lexing.position * Lexing.position)
                (initial : 'a Inter.checkpoint) =
          let initial = Correct initial in
          let errors = ref [] in
          let rec loop parser =
            match supplier () with
            | exception LexingError msg -> Stdlib.Error (msg, !errors)
            | token ->
               let (s, error) = (step parser failure token) in
               begin match error with
               | Some error -> errors := error :: !errors;
               | None       -> ()
               end;
               match s with
               | Success x              -> Stdlib.Ok (success x, !errors)
               | Intermediate (parser)  -> loop parser
               (* Fatal recovery error !!! *)
               | Error cp               -> Stdlib.Error (failure cp, !errors)
          in loop initial
      end

    let get_message_on_failure (module ParErr : PAR_ERR) checkpoint =
      let msg = get_error_message (module ParErr) checkpoint in
      let window = get_window () in
      let region = Token.to_region window#current_token
      in Region.{value = msg; region}

    let incr_menhir_recovery lexbuf_of (module ParErr : PAR_ERR) source =
      let lexbuf       = lexbuf_of source
      and menhir_lexer = mk_menhir_lexer Lexer.scan in
      let supplier     = Inter.lexer_lexbuf_to_supplier menhir_lexer lexbuf in
      let failure      = get_message_on_failure (module ParErr) in
      let interpreter  = Recover.loop_handle success failure supplier in
      let module Incr  = Parser.Incremental in
      let parser       = Incr.main lexbuf.Lexing.lex_curr_p in
      let result       = interpreter parser
      in flush_all (); result

    let recov_from_lexbuf  = incr_menhir_recovery (fun x -> x)
    let recov_from_channel = incr_menhir_recovery Lexing.from_channel
    let recov_from_string  = incr_menhir_recovery Lexing.from_string

    let recov_from_file (module ParErr : PAR_ERR) path =
      match lexbuf_from_file path with
        Stdlib.Error err   -> Stdlib.Error (err, [])
      | Ok (lexbuf, close) ->
         let r = recov_from_lexbuf (module ParErr) lexbuf
         in close (); r
  end
